## 问题

当一个 job 实际使用的 cpu 和 memory 超过设置的 limit 时，可能会被杀死，因而需要手动去调整其 limit，这一操作手动是非常低效的。

通过动态调整 cpu 和 memory 的 limit（纵向调整），以及 job 中 tasks 的数量（横向调整），来最小化 slack （实际使用的资源量和 limit 之间的差距），同时最小化 tasks 因为资源不够而被限制或杀死的风险

---

## 简介和一些背景

- 用户通常对 limit 的设置，和并行 tasks 的数量（replica）是把握不好的
- Load test 可以给出一个初始的估计值，但是不能预测后期程序使用资源的走势（因为很多应用是有周级别或者更长时间的 pattern）
- 因此理智的用户会给出一个非常高估的值，从而有一个比较大的安全边界，但这样资源的利用率就非常低了
- 一个月的记录：Google 集群的平均资源利用率 50%，阿里的 YARN 集群最高 memory 利用率没有超过 80%
- 传统的方法只有横向调整，也就是增减 replica 的数量。另外一个比较少见的是纵向调整，也就是对每一个 replica 调整他可用的资源大小。这两种技术可以被合并
- 本篇论文讨论了两种纵向调整的方法，第一种是基于历史记录的 exponentially-smoothed sliding window，另一种是类似强化学习，运行许多不同参数的同一个 sliding window 算法，选最好的一组参数从而让历史表现最好

### job, task 和 machine 的关系

job 是指的一个具体的 functionality，它一般由若干个 tasks 组成。在一个 machine 上，会同时运行许多个 tasks。

### workloads 的种类

- serving：要保证反应时间在一定阈值以下，例如 SLO <= 50ms
- batch：要尽快地完成并退出

---

## 采样数据

#### CPU

每五分钟为一个单位，记录 cpu 使用的直方图。具体来说，有 400 个频段，然后以 1 秒为采样频率，统计五分钟内 cpu 使用量（raw signal samples，不清楚具体的单位）在每个频段的频次。得到一个直方图。

#### Memory

只记录峰值。这是因为 cpu 低估了一些问题不大（只会导致 cpu 限流），但内存一旦不够就会导致 OOM，直接结束 task

---

## 初始 cpu 和 memory 的值

另一个 work [35]

J. Wilkes. Google cluster usage traces v3. Technical report at h￿ps:
//github.com/google/cluster-data, Google, Mountain View, CA, USA, 2020.

---

## Exponentially-smoothed Sliding Window

对于历史最近一段时间的均值，使用的是 指数衰减函数。目的是我们希望推荐值随着对增长的需求反应非常灵敏，但是随着需求减少的时候，推荐值下降得比较慢（留出较大的安全空间）

【TODO: 为什么这个函数可以有这样的性质】

半衰期这里用的是 12 hr（对于 cpu）和 48 hr（对于 memory）

#### 基于历史值有三种方法获得针对 cpu 和 memory 的建议值

- peak (S_max): 过去 N 个时间单位内的最大值。对于 CPU 来说，是出现过的最大使用量

- weighted average (S_avg): 对前 0 ... inf 个时间单位做加权平均，第前 i 个时间单位的权重为 w[i]。对于 cpu 某个时间段的直方图，用他的平均值做加权

- j-%ile of adjusted usage (S_pj): 首先对直方图做 load-adjusted，也就是每个频段的频数 都对最近一段时间的值做指数衰减加权平均，然后乘以这个频段的频率。比如这个频段对应 cpu 使用率是 t，那么它加权后的频数是 x，我们最后会取成 $$x * t$$。然后我们就取这个直方图的百分之 j 分位的数，作为我们的推荐值

（解释这个方法的一个例子是，比如我们记录了十个时间单位的 cpu 用量，前九个时间单位都为 1，但最后为 10。我们想取 90% 分位为推荐值。如果我们以时间为横轴取，为 1 1 1 1 1 1 1 1 1 10，如果我们取 90% 分位值作为推荐值，那就是 1，但是这样的话实际上有差不多一半的 load 没办法被满足（最后一分钟内），因为这样的做法对于每个时间单位里不同使用量，给的权重是一致的，也就是把所有数据展开以后，即使有少数时间使用量非常大，他也只在这个序列中占一个位置，取分位数的时候占不到优势。但如果我们把最后一个单位 给 10 的权重，即用使用量当权重，那么数列展开以后是 1 1 ... 1 10 10 ... 10，这样再取分位数的时候，10 就有相当大的优势，90% 分位数就会变成了 10，就可以覆盖所有要求）

#### 三种方法的使用场景

对于 CPU:

- batch job: 用的是 weighted average，因为我们默认这些 job 可以容许一段时间内 cpu 使用超过 limit 从而被限流，但是可以保证整体上的使用量满足需求，即不会长时间的造成阻塞

- serving job: 用的是 j-%ile of adjusted usage，因为要保证绝大部分时间的 cpu 使用都不超过 limit，这个方法在意的是 “大部分时间内可能出现的使用率都在这个范围内”。一般 j 为 90 或者 95，取决于 job 对 latency 的要求

对于 Memory:

定义了一个关于 OOM 的容忍度，对于绝大多数的大的 job，设置为 "low"，然后对于小任务，设置成 "minimal"，还有一个 "intermediate" 的选项。这个选项可以被用户重新设定

- 对于 low 的 job：用的是 j-%ile of adjusted usage， S_p98

- 对于 minimal 的 job：用的是 S_max，即用历史峰值作为推荐值

- 对于 intermediate 的 job：用 S_p60 或 0.5S_max，我们只需要靠考虑覆盖峰值的一部分

在最开始，我们都会给这些 raw recommandation 加上 10-15% 的安全边界（对于 limit 较大的，安全边界较小）。运行了一段时间以后，我们选用过去一段时间里给出的最大推荐值作为新的推荐值

---

## 基于机器学习的推荐值

### 问题建模

对于一个 job，根据它的历史 usage，要找一个 limit，使得它对于一个关于 job 和 infrastructure 资源的函数 最优。

### 流程

和传统的机器学习一样，先找一个 cost 函数，其描述了我们想要的理想状态，然后对每一个 job，选择适合的 parameter 来优化这个函数。基于上一个方法，机器学习让我们可以对每一个 job 找到专属于他们的最优参数，比如 质数衰减函数中的半衰期，比如最优的 安全边界值。

在 ML Recommander 的内部，有若干个简单的模型（这些模型的参数值 $$d_m$$ 和 $$M_m$$ 不一样），其会选择在一个 job 的历史数据上表现最好的一个模型，来给出推荐值。

一个常见的问题是，我们给出的推荐值，是需要对 job owner 来说可解释的。因此我们拥有多个模型的原因是，可能某一种类型的 job，会有非常适合它的 model（比如 对于使用资源变化剧烈的 job，最好的模型偏向于给出长时间稳定的推荐值），这样给出的结果是比较可解释的。

### cost 函数

在一个时间段 t，对于一个给定的推荐值 L，我们考虑这个时间节点的直方图 s[t]。分别计算 L 在这个时间段内 overrun 的次数 o(L)[t]（L > 使用量）和 underrun 的次数 u(L)[t]（L < 使用量），对于 o 和 u，我们都会与之前时间段的 o 和 u 进行指数衰减加权（根据 d_m，衰减系数）。此外，我们额外考虑一个惩罚函数 △，如果 t 给出的推荐值和上一个时间段 t - 1 的推荐值不同，则函数值为 1，否则为 0。

那么在时间段 t 的 cost 函数即为

$$w_o * o(L)[t] + w_u * u(L)(t) + w_△ * △$$

假设模型 m 在 t 时刻给出的推荐值是 $$L_m(t)$$，那么最后采用的值为 $$L_m(t) + M_m$$，$$M_m$$ 是一个安全边界。

因为我们有多个模型，因此在运行时，我们对每个模型都要维护一个 cost 函数 $$c_m(t)$$，从而来选择每个时刻最好的 model。对于一个 model m 来说，他在 t 时刻的 cost 来自于：

- 在 t 给出的推荐值 $$L_m(t)$$ 带来的 cost

- 历史的 cost 指数衰减加权和

的加权（基于一个衰减率 d）。

最后，对于 recommander，它需要在每个时间选择一个 model，那么对它来说它的优化目标是对于 m 的一个 arg min 函数，cost 是

- m 的 c_m(t)

- 切换模型的惩罚 $$w_{△m} * △(m, m[t - 1])$$

- 变换推荐值的惩罚 $$w_{△L} * △(L[t], L_m[t])$$

三者的和。因此我们有五个 hyperparameter 去 train，分别是 $$d, w_o, w_u, w_{△m}, w_{△L}$$。注意，许多”简单的模型“的意思是，我们提前给定一堆预设好的 $$d_m$$ 和 $$M_m$$。
